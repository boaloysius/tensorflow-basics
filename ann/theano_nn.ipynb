{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import theano\n",
    "\n",
    "from util import get_normalized_data, y2indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def error_rate(p, t):\n",
    "    return np.mean(p!=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(a):\n",
    "    return a * (a>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    X, Y = get_normalized_data()\n",
    "    \n",
    "    # Setting usual variables\n",
    "    max_iter = 20\n",
    "    print_period = 10\n",
    "    lr = 0.00004\n",
    "    reg = 0.01\n",
    "    \n",
    "    # Setting data\n",
    "    Xtrain = X[:-1000,]\n",
    "    Ytrain = Y[:-1000,]\n",
    "    Xtest = X[-1000:,]\n",
    "    Ytest = Y[-1000:,]\n",
    "    Ytrain_ind = y2indicator(Ytrain)\n",
    "    Ytest_ind = y2indicator(Ytest)\n",
    "    \n",
    "    N,D = Xtrain.shape\n",
    "    batch_sz = 500\n",
    "    n_batches = N/batch_sz\n",
    "    \n",
    "    # Creating initial weights and biases\n",
    "    M=300\n",
    "    K=10\n",
    "    W1_init = np.random.randn(D,M)/28\n",
    "    b1_init = np.zeros(M)\n",
    "    W2_init = np.random.randn(M,K)/np.sqrt(M)\n",
    "    b2_init = np.zeros(K)\n",
    "    \n",
    "    # Creating theano Variables and model\n",
    "    # We use Variables for the inputs and\n",
    "    # Shared Variables for weights and biases as it need to be updated\n",
    "    thX = T.matrix('X')\n",
    "    thT = T.matrix('T')\n",
    "    W1 = theano.shared(W1_init,'W1')\n",
    "    b1 = theano.shared(b1_init,'b1')\n",
    "    W2 = theano.shared(W2_init,'W2')\n",
    "    b2 = theano.shared(b2_init,'b2')\n",
    "    thZ = relu(thX.dot(W1) + b1)\n",
    "    thY = T.nnet.softmax(thZ.dot(W2)+b2)\n",
    "    \n",
    "    # Cost and Prediction\n",
    "    cost = -(thT * T.log(thY)).sum() + reg*((W1*W1).sum() + (b1*b1).sum()+ (W2*W2).sum() + (b2*b2).sum())\n",
    "    prediction = T.argmax(thY, axis=1)\n",
    "    \n",
    "    # Weight update model\n",
    "    update_W1 = W1 - lr*T.grad(cost, W1)\n",
    "    update_b1 = b1 - lr*T.grad(cost, b1)\n",
    "    update_W2 = W2 - lr*T.grad(cost, W2)\n",
    "    update_b2 = b2 - lr*T.grad(cost, b2)\n",
    "    \n",
    "    # train is the function used to update the weights and biases in the model\n",
    "    train = theano.function(\n",
    "        inputs = [thX, thT],\n",
    "        updates=[(W1,update_W1),(b1,update_b1),(W2,update_W2),(b2,update_b2)]\n",
    "    )\n",
    "\n",
    "    \n",
    "    get_prediction = theano.function(\n",
    "        inputs = [thX, thT],\n",
    "        outputs = [cost,prediction]\n",
    "    )\n",
    "    \n",
    "    costs = []\n",
    "    for i in xrange(max_iter):\n",
    "        for j in xrange(n_batches):\n",
    "            X_batch = Xtrain[j*batch_sz:(j+1)*batch_sz,]\n",
    "            Y_batch = Ytrain_ind[j*batch_sz:(j+1)*batch_sz,]\n",
    "            train(X_batch, Y_batch)\n",
    "            \n",
    "            if(j%print_period == 0):\n",
    "                cost_val, prediction_val = get_prediction(Xtest, Ytest_ind)\n",
    "                err = error_rate(prediction_val, Ytest)\n",
    "                print \"Cost/err at iteration i=%d, j=%d: %.3f / %.3f\" % (i,j,cost_val,err)\n",
    "                costs.append(cost_val)\n",
    "    return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n",
      "Cost/err at iteration i=0, j=0: 2528.421 / 0.929\n",
      "Cost/err at iteration i=0, j=10: 1847.631 / 0.537\n",
      "Cost/err at iteration i=0, j=20: 1472.523 / 0.358\n",
      "Cost/err at iteration i=0, j=30: 1232.594 / 0.280\n",
      "Cost/err at iteration i=0, j=40: 1065.867 / 0.227\n",
      "Cost/err at iteration i=0, j=50: 944.591 / 0.206\n",
      "Cost/err at iteration i=0, j=60: 853.558 / 0.185\n",
      "Cost/err at iteration i=0, j=70: 779.955 / 0.170\n",
      "Cost/err at iteration i=0, j=80: 721.758 / 0.159\n",
      "Cost/err at iteration i=1, j=0: 710.788 / 0.157\n",
      "Cost/err at iteration i=1, j=10: 666.205 / 0.151\n",
      "Cost/err at iteration i=1, j=20: 628.936 / 0.146\n",
      "Cost/err at iteration i=1, j=30: 596.179 / 0.142\n",
      "Cost/err at iteration i=1, j=40: 568.228 / 0.137\n",
      "Cost/err at iteration i=1, j=50: 544.723 / 0.129\n",
      "Cost/err at iteration i=1, j=60: 524.889 / 0.128\n",
      "Cost/err at iteration i=1, j=70: 506.065 / 0.124\n",
      "Cost/err at iteration i=1, j=80: 489.277 / 0.119\n",
      "Cost/err at iteration i=2, j=0: 485.891 / 0.117\n",
      "Cost/err at iteration i=2, j=10: 471.616 / 0.113\n",
      "Cost/err at iteration i=2, j=20: 459.235 / 0.116\n",
      "Cost/err at iteration i=2, j=30: 446.932 / 0.113\n",
      "Cost/err at iteration i=2, j=40: 436.143 / 0.108\n",
      "Cost/err at iteration i=2, j=50: 426.541 / 0.105\n",
      "Cost/err at iteration i=2, j=60: 417.974 / 0.105\n",
      "Cost/err at iteration i=2, j=70: 409.663 / 0.103\n",
      "Cost/err at iteration i=2, j=80: 401.564 / 0.096\n",
      "Cost/err at iteration i=3, j=0: 399.993 / 0.098\n",
      "Cost/err at iteration i=3, j=10: 392.738 / 0.095\n",
      "Cost/err at iteration i=3, j=20: 386.475 / 0.096\n",
      "Cost/err at iteration i=3, j=30: 379.845 / 0.096\n",
      "Cost/err at iteration i=3, j=40: 373.857 / 0.093\n",
      "Cost/err at iteration i=3, j=50: 368.536 / 0.091\n",
      "Cost/err at iteration i=3, j=60: 363.517 / 0.091\n",
      "Cost/err at iteration i=3, j=70: 358.843 / 0.089\n",
      "Cost/err at iteration i=3, j=80: 353.896 / 0.089\n",
      "Cost/err at iteration i=4, j=0: 353.008 / 0.088\n",
      "Cost/err at iteration i=4, j=10: 348.309 / 0.088\n",
      "Cost/err at iteration i=4, j=20: 344.442 / 0.090\n",
      "Cost/err at iteration i=4, j=30: 340.315 / 0.087\n",
      "Cost/err at iteration i=4, j=40: 336.415 / 0.085\n",
      "Cost/err at iteration i=4, j=50: 332.882 / 0.084\n",
      "Cost/err at iteration i=4, j=60: 329.380 / 0.087\n",
      "Cost/err at iteration i=4, j=70: 326.384 / 0.086\n",
      "Cost/err at iteration i=4, j=80: 322.962 / 0.083\n",
      "Cost/err at iteration i=5, j=0: 322.414 / 0.083\n",
      "Cost/err at iteration i=5, j=10: 318.930 / 0.083\n",
      "Cost/err at iteration i=5, j=20: 316.204 / 0.082\n",
      "Cost/err at iteration i=5, j=30: 313.337 / 0.083\n",
      "Cost/err at iteration i=5, j=40: 310.522 / 0.082\n",
      "Cost/err at iteration i=5, j=50: 307.892 / 0.082\n",
      "Cost/err at iteration i=5, j=60: 305.205 / 0.082\n",
      "Cost/err at iteration i=5, j=70: 303.177 / 0.083\n",
      "Cost/err at iteration i=5, j=80: 300.624 / 0.081\n",
      "Cost/err at iteration i=6, j=0: 300.282 / 0.080\n",
      "Cost/err at iteration i=6, j=10: 297.473 / 0.080\n",
      "Cost/err at iteration i=6, j=20: 295.517 / 0.081\n",
      "Cost/err at iteration i=6, j=30: 293.365 / 0.080\n",
      "Cost/err at iteration i=6, j=40: 291.174 / 0.078\n",
      "Cost/err at iteration i=6, j=50: 289.071 / 0.079\n",
      "Cost/err at iteration i=6, j=60: 286.833 / 0.077\n",
      "Cost/err at iteration i=6, j=70: 285.407 / 0.078\n",
      "Cost/err at iteration i=6, j=80: 283.411 / 0.077\n",
      "Cost/err at iteration i=7, j=0: 283.200 / 0.077\n",
      "Cost/err at iteration i=7, j=10: 280.834 / 0.076\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    costs = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(costs)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
