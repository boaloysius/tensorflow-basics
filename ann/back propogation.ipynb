{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(X, W1, b1, W2, b2):\n",
    "    a1 = X.dot(W1) + b1\n",
    "    z= 1/(1+np.exp(-a1))\n",
    "    a2 = z.dot(W2) + b2\n",
    "    expA = np.exp(a2)\n",
    "    y = expA/expA.sum(axis=1, keepdims=True)\n",
    "    return y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_rate(Y, P):\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    for i in xrange(len(Y)):\n",
    "        n_total += 1\n",
    "        if Y[i] == P[i] :\n",
    "            n_correct+=1\n",
    "    return float(n_correct)/n_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def derivative_w2(Z,T,Y):\n",
    "    N,K = T.shape\n",
    "    M = Z.shape[1]\n",
    "    \n",
    "    #slow\n",
    "    rest1 = np.zeros((M,K))\n",
    "    \n",
    "    for n in xrange(N):\n",
    "        for m in xrange(M):\n",
    "            for k in xrange(K):\n",
    "                ret1[m,k] += (T[n,k] - Y[n,k]) *Z[n,m]\n",
    "    return ret1\n",
    "\n",
    "def derivative_b2(T,Y):\n",
    "    return (T-Y).sum(axis=0)\n",
    "\n",
    "def derivative_w1(X,Z,T,Y,W2):\n",
    "    N,D = X.shape\n",
    "    M,K = W2.shape\n",
    "    \n",
    "    #slow\n",
    "    ret1 = np.zeros((D,M))\n",
    "    for n in xrange(N):\n",
    "        for l in xrange(K):\n",
    "            for m in xrange(M):\n",
    "                for d in xrange(D):\n",
    "                    ret1[d,m] += (T[n,k] - Y[n,k] * W2[m,k]*Z[n,m] * (1-Z[n,m])*X[n,d])\n",
    "                    \n",
    "    return ret1\n",
    "\n",
    "def derivative_b1(T,Y,W2,Z):\n",
    "    return ((T-Y).dot(W2,T) * Z*(1-Z)).sum(axis=0)\n",
    "        \n",
    "def cost(T, Y):\n",
    "    tot = T*np.log(Y)\n",
    "    return tot.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (<ipython-input-11-7441439eed9b>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-7441439eed9b>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    T(i,Y[i]) = 1\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Set the variables of the network\n",
    "    Nclass = 500\n",
    "    D = 2 #Input dimensionality\n",
    "    M = 3 #Hidden layer size\n",
    "    K = 3 #Output classes\n",
    "\n",
    "    X1 = np.random.randn(Nclass, 2) + np.array([0,-2])\n",
    "    X2 = np.random.randn(Nclass, 2) + np.array([2,2])\n",
    "    X3 = np.random.randn(Nclass, 2) + np.array([-2,2])\n",
    "    X = np.vstack([X1,X2,X3])\n",
    "    \n",
    "    Y = np.array([0]*Nclass + [1]*Nclass + [2]*Nclass)\n",
    "    \n",
    "    # We create T as a array of one hot vector on K classes.\n",
    "    \n",
    "    N = len(Y)\n",
    "    T = np.zeros((N,K))\n",
    "    for i in xrange(N):\n",
    "        T(i,Y[i]) = 1\n",
    "        \n",
    "    plt.scatter(X[:,0],X[:,1], alpha=0.5, c=Y, scale=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # Randomly initializing the weights\n",
    "    W1 = np.random.randn(D,M)\n",
    "    b1 = np.random.randn(M)\n",
    "    W2 = np.random.randn(M,K)\n",
    "    b2 = np.random.randn(K)\n",
    "    \n",
    "    learning_rate = 10e-7\n",
    "    \n",
    "    cost = []\n",
    "    for epoch in xrange(100000):\n",
    "        output, hiddedn = forward(X,W1,b1,W2,b2)\n",
    "        if (epoch % 100 == 0):\n",
    "            c = cost(T, output)\n",
    "            P = np.argmax(output,axis=1)\n",
    "            r = classification_rate(Y, P)\n",
    "            print \"cost: \", c, \"classification_rate:\", r\n",
    "            costs.append(c)\n",
    "        \n",
    "        # We are going to do Gradient Ascent\n",
    "        W2 += learning_rate * derivative_w2(hidden,T, output)\n",
    "        b2 += learning_rate * detivative_b2(T, output)\n",
    "        W1 += learning_rate * derivative_w1(X, hidden, T, output, w2)\n",
    "        b1 += learning_rate * derivative_b1(T, output, W2, hidden)\n",
    "        \n",
    "        plt.plot(costs)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == 'main':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
